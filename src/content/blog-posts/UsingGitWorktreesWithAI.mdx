---
title: "Software development superpowers with git worktrees, tmux, and parallel agents"
slug: git-worktrees-agents-and-tmux
summary: >-
  If you feel underwhelmed with AI codegen products or just want more out of them, you should give git worktrees and parallel inference a shot. I'm willing to call myself an evangelist after seeing the results firsthand over the past month. Throughput improvements are incredible and I don't feel like I'm losing control of the codebase.
author: Nicholas Khami
createdAt: 2024-05-26T18:52:00.000Z
updatedAt: 2024-05-26T18:52:00.000Z
coverImage: src/assets/images/blog-posts/UsingGitWorktreesWithAI/open-graph.png
displayCoverImage: false
isDraft: false
isFeatured: true
categories:
  - ai
  - vcs
---

import Pile from "../../components/blog/UsingGitWorktreesWithAI/Pile.astro";

This realization isn't unique to me; the effectiveness of using Git worktrees for simultaneous execution is gaining broader recognition, as evidenced by mentions in [Claude Code's docs](https://docs.anthropic.com/en/docs/claude-code/tutorials#run-parallel-claude-code-sessions-with-git-worktrees), [discussion on Hacker News](https://news.ycombinator.com/item?id=44043717), projects like [Claude Squad](https://github.com/smtg-ai/claude-squad), and conversation on [X](https://x.com/search?q=git%20worktree&src=typed_query&f=live).

<Pile />

### Personal example building a UI component

I am building a component library called [astrobits](https://astrobits.dev) and wanted to add a `Toggle` component. To tackle the task, I rolled out two [Claude Code](https://www.anthropic.com/claude-code) and two [Codex](https://openai.com/index/introducing-codex/) agents, each running in parallel within their own isolated [git worktrees](https://git-scm.com/docs/git-worktrees). Worktrees are essential because they provide each agent with an isolated working directory. Without this isolation, agents would overwrite each other's changes, creating confusion and wasted effort.

Number of agents I choose to run depends on the complexity of the task. For simpler tasks, two agents are usually sufficient. For moderately complex tasks, three to five agents work well. For the most challenging tasks, six or more agents may be necessary. Over time, you'll develop an intuition for estimating the right number of agents based on the task at hand. Here, I felt like 4 was appropriate.

Voila, results! Only one of the four agents produced a solution that actually saved me time. I probably needed to run more agents, but it's fine. Before parallel agents, I would have gotten a single output that didn't work and then likely give up and do it myself. Now, I have a working solution that I can build on and feel that AI is awesome. It's also not much more expensive in terms of cost magnitude, we are talking going from $0.10 to $0.40 for the task, which is a drop in the bucket compared to the value of the time saved.

<ImageFourSquareWorktrees />

If the tooling were better, I could have just re-ran the process from scratch with 8 agents instead of having to do any manual work whatsoever. Low-level day to day of using parallel agents is still far from a frictionless experience.

### Raw workflow pain points

Currently, I manually create git worktrees using `git worktree add -b newbranch ../path`, start a `tmux` session for each one, run Claude Code in the first pane, paste a prompt, `leader+c` into a new pane, run `yarn dev` to get a preview, switch to my browser to review, re-prompt if no agents succeed, and finally commit, push, and create a PR once I'm satisfied with the results.

Here are the top pain points:

- I can't tell which branch a worktree was most recently rebased onto, which is disorienting when juggling multiple agents.
- There is no easy way to send the same prompt to multiple agents at once. I'm manually copy-pasting everything like an animal.
- Setting up a shared starter state across agents is too much work. It needs to be much easier to spawn off a non-main branch with a predefined set of manual changes.
- I really wish I had a shortcut to open VS Code for a given worktree without having to `tmux a`, `leader + c`, and `code .` manually.
- Agents often fail in the same way, and repeating the same prompt or fix across them is too repetitive. I should be able to broadcast a followup prompt to all agents at once and move on.
- Web previewing is a pain. I have to manually run `yarn dev` in each worktree, and then hold the mental model of which port each worktree is on. Automating a reverse proxy to handle this with a decent naming scheme would be a game-changer.

### Proposing a solution: `uzi`

To address these challenges head-on, the ideal developer experience (DX) would involve a lightweight CLI that wraps tmux, automating this complex orchestration. My co-founder Denzell and I felt these pain points acutely enough that we've begun developing such a tool, which we're calling [uzi](https://github.com/devflowinc/uzi). The core idea behind `uzi` is to abstract away the manual, repetitive tasks involved in managing multiple AI agent worktrees.

For example, `uzi` aims to simplify common operations:

- `uzi start --agents claude:3,codex:2 --prompt "Implement feature X"` could initialize and prompt three Claude instances and two Codex instances, each in its own worktree.
- `uzi ls` would display all active agents, their target branches, and current statuses.
- `uzi exec --all -- yarn dev` could run a command like `yarn dev` across all agent worktrees.
- `uzi broadcast -- "Refine the previous response by focusing on Y"` would send a follow-up prompt to all active agents.
- `uzi checkpoint --agent claude-1 --message "Implemented initial draft"` could rebase the specified agent's worktree and commit the changes.
- `uzi kill --agent codex-2` would clean up a specific agent's tmux session and optionally its worktree.

These commands would primarily operate by sending `tmux send-keys` instructions to the appropriate sessions. We don't want to reinvent the wheel; we just want to polish the existing process and make it more efficient.

### The Future is Parallel: Beyond Code

While `uzi` focuses on software developers, its methodology isn't limited to tech; the principle of leveraging multiple agents running in parallel to increase the odds of finding an optimal solution applies universally.

Consider a company like [versionstory](https://www.versionstory.com/), which is pioneering version control for transactional lawyers. An attorney could leverage their software to run multiple instances of an agent to redline a contract. After reviewing the outputs, they could select and merge the best components to finalize the document. This approach would provide additional confidence in the quality of the final review as it would be based on multiple independent analyses rather than a single agent's output.

Similarly, a marketing team could employ this parallel strategy to perform data analysis on ad performance. By prompting multiple AI instances, they could quickly gather a range of analyses, review them, and select the most insightful ones to inform their strategy. More coverage of the solution space leads to better decision-making and more effective campaigns.

This parallel paradigm isn't just a new technique for developers; it's a glimpse into a more efficient, robust, and powerful future for AI-assisted productivity across various fields. I expect to see existing software products start to gain more powerful version control and parallel execution capabilities which emulate the workflow enabled by git worktrees for software and enable this "AI Fiverr Method" for AI across industries.
