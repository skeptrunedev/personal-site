---
title: "The 'Fiverr Method' for AI: Using Git Worktrees to Run Agents in Parallel"
slug: git-worktrees-with-AI
summary: >-
  I struggled to boost my productivity with AI until I started using git worktrees to run multiple agents in parallel with the same prompt, which completely transformed my experience.
author: Nicholas Khami
createdAt: 2024-05-26T18:52:00.000Z
updatedAt: 2024-05-26T18:52:00.000Z
coverImage: src/assets/images/blog-posts/UsingGitWorktreesWithAI/open-graph.png
displayCoverImage: false
isDraft: false
isFeatured: true
categories:
  - ai
  - vcs
---

import Pile from "../../components/Pile.astro";

Others have had similar results, as evidenced by mentions of Git worktrees in [Claude Code's docs](https://docs.anthropic.com/en/docs/claude-code/tutorials#run-parallel-claude-code-sessions-with-git-worktrees), [discussion on Hacker News](https://news.ycombinator.com/item?id=44043717), projects like [Claude Squad](https://github.com/smtg-ai/claude-squad), and conversation on [X](https://x.com/search?q=git%20worktree&src=typed_query&f=live).

<Pile />

### Why worktrees pair well with AI

My favorite metaphor for the AI worktree development process is that it's similar to how you might [hire multiple people on Fiverr to work on the same task](https://x.com/garrytan/status/1918027171039461435) to see who delivers the best results. Humans on Fiverr naturally work in isolation since they each bring their own working environment without sharing common state.

This isolation is exactly what agents need to run in parallel, but it's hard to achieve with standard git in a single directory. Multiple agents in one folder can overwrite each other's changes, causing confusion. [Git worktrees](https://git-scm.com/docs/git-worktrees) solve this by creating isolated working directories that share the same repository. Each worktree can have its own branch and agent, allowing you to run multiple simultaneously without interference.

While more complex and costly in terms of tokens than using a single agent, this pattern offers quality advantages due to the stochastic nature of codegen agents. Running multiple instances with identical prompts effectively creates a [Monte Carlo process](https://en.wikipedia.org/wiki/Monte_Carlo_method), rather than depending on a single potentially suboptimal output, you can compare results from several agents, select the best one, or combine elements to create an optimal solution.

The number of agents you run can be adjusted based on the complexity of the task. For instance, when trying to solve a challenging Rust backend issue, I would run 5, while for a basic React component, just 2 would suffice. Worktrees make this elastic scalability seamless, allowing you run as many agents as needed without cluttering your main branch or repository.

### Current state of the art: manual worktrees and tmux

I've been using git worktrees with AI agents for a while now, and while it has significantly improved my productivity, the process is still quite manual and cumbersome.

Currently, I manually create git worktrees using `git worktree add -b newbranch ../path`, start a `tmux` session for each worktree, run Claude Code in the first pane, paste a prompt, use `leader+c` to open a new pane, run `yarn dev` to get a preview, switch to my browser to review, re-prompt if no agents succeed, and finally commit, push, and create a PR once I'm satisfied with the results.

Here are the top pain points:

- I can't tell which branch a worktree was most recently rebased onto, which is disorienting when juggling multiple agents.
- There is no way to send the same prompt to multiple agents at once. I'm manually copy-pasting everything like an animal.
- Setting up a shared starter state across agents is too much work. It needs to be much easier to spawn off a non-main branch with a predefined set of manual changes.
- I really wish I had a shortcut to open VS Code for a given worktree without having to `tmux a`, `leader + c`, and `code .` manually.
- Agents often fail in the same way, and repeating the same prompt or fix across them is too repetitive. I should be able to broadcast a followup prompt to all agents at once and move on.
- Web previewing is a pain. I have to manually run `yarn dev` in each worktree, and then hold the mental model of which port each worktree is on. Automating a reverse proxy to handle this with a decent naming scheme would be a game-changer.

### Proposing a solution: `uzi`

To address these challenges head-on, the ideal developer experience (DX) would involve a lightweight CLI that wraps tmux, automating this complex orchestration. My co-founder Denzell and I felt these pain points acutely enough that we've begun developing such a tool, which we're calling [uzi](https://github.com/devflowinc/uzi). The core idea behind `uzi` is to abstract away the manual, repetitive tasks involved in managing multiple AI agent worktrees.

For example, `uzi` aims to simplify common operations:

- `uzi start --agents claude:3,codex:2 --prompt "Implement feature X"` could initialize and prompt three Claude instances and two Codex instances, each in its own worktree.
- `uzi ls` would display all active agents, their target branches, and current statuses.
- `uzi exec --all -- yarn dev` could run a command like `yarn dev` across all agent worktrees.
- `uzi broadcast -- "Refine the previous response by focusing on Y"` would send a follow-up prompt to all active agents.
- `uzi checkpoint --agent claude-1 --message "Implemented initial draft"` could rebase the specified agent's worktree and commit the changes.
- `uzi kill --agent codex-2` would clean up a specific agent's tmux session and optionally its worktree.

These commands would primarily operate by sending `tmux send-keys` instructions to the appropriate sessions, streamlining the workflow.

### The Future is Parallel: Beyond Code

While `uzi` focuses on software developers, this "Fiverr Method" for AI isn't limited to tech; the principle of leveraging multiple agents running in parallel to increase the odds of finding an optimal solution applies universally.

Consider a company like [versionstory](https://www.versionstory.com/), which is pioneering version control for transactional lawyers. An attorney could avoid "copilot pause" by running multiple instances of an agent to redline a contract. After reviewing the outputs, they could select and merge the best components to finalize the document. This approach would provide additional confidence in the quality of the final review as it would be based on multiple independent analyses rather than a single agent's output.

Similarly, a marketing team could employ this parallel strategy to perform data analysis on ad performance. By prompting multiple AI instances, they could quickly gather a range of analyses, review them, and select the most insightful ones to inform their strategy. More coverage of the solution space leads to better decision-making and more effective campaigns.

This parallel paradigm isn't just a new technique for developers; it's a glimpse into a more efficient, robust, and powerful future for AI-assisted productivity across various fields.
